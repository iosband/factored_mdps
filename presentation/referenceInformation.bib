@article{jaksch2010near,
  title={Near-optimal regret bounds for reinforcement learning},
  author={Jaksch, Thomas and Ortner, Ronald and Auer, Peter},
  journal={The Journal of Machine Learning Research},
  volume={99},
  pages={1563--1600},
  year={2010},
  publisher={MIT Press}
}

@inproceedings{strehl2006pac,
  title={PAC model-free reinforcement learning},
  author={Strehl, Alexander L and Li, Lihong and Wiewiora, Eric and Langford, John and Littman, Michael L},
  booktitle={Proceedings of the 23rd international conference on Machine learning},
  pages={881--888},
  year={2006},
  organization={ACM}
}

@article{osband2014model,
  title={Model-based Reinforcement Learning and the Eluder Dimension},
  author={Osband, Ian and Van Roy, Benjamin},
  journal={arXiv preprint arXiv:1406.1853},
  year={2014}
}

@article{van2014generalization,
  title={Generalization and Exploration via Randomized Value Functions},
  author={Van Roy, Benjamin and Wen, Zheng},
  journal={arXiv preprint arXiv:1402.0635},
  year={2014}
}

@inproceedings{kleinberg2008multi,
  title={Multi-armed bandits in metric spaces},
  author={Kleinberg, Robert and Slivkins, Aleksandrs and Upfal, Eli},
  booktitle={Proceedings of the 40th annual ACM symposium on Theory of computing},
  pages={681--690},
  year={2008},
  organization={ACM}
}

@inproceedings{bubeck2008online,
  title={Online Optimization in X-Armed Bandits.},
  author={Bubeck, S{\'e}bastien and Munos, R{\'e}mi and Stoltz, Gilles and Szepesv{\'a}ri, Csaba and others},
  booktitle={NIPS},
  pages={201--208},
  year={2008}
}

@inproceedings{diuk2009adaptive,
  title={The adaptive k-meteorologists problem and its application to structure learning and feature selection in reinforcement learning},
  author={Diuk, Carlos and Li, Lihong and Leffler, Bethany R},
  booktitle={Proceedings of the 26th Annual International Conference on Machine Learning},
  pages={249--256},
  year={2009},
  organization={ACM}
}

@inproceedings{strehl2007online,
  title={Online Linear Regression and Its Application to Model-Based Reinforcement Learning.},
  author={Strehl, Alexander L and Littman, Michael L},
  booktitle={NIPS},
  year={2007}
}

@inproceedings{ortner2012online,
  title={Online Regret Bounds for Undiscounted Continuous Reinforcement Learning.},
  author={Ortner, Ronald and Ryabko, Daniil and others},
  booktitle={NIPS},
  pages={1772--1780},
  year={2012}
}

@article{abbasi2011regret,
  title={Regret Bounds for the Adaptive Control of Linear Quadratic Systems.},
  author={Abbasi-Yadkori, Yasin and Szepesv{\'a}ri, Csaba},
  journal={Journal of Machine Learning Research-Proceedings Track},
  volume={19},
  pages={1--26},
  year={2011}
}

@article{sanner2012approximate,
  title={Approximate linear programming for first-order {MDP}s},
  author={Sanner, Scott and Boutilier, Craig},
  journal={arXiv preprint arXiv:1207.1415},
  year={2012}
}

@article{delgado2011efficient,
  title={Efficient solutions to factored {MDP}s with imprecise transition probabilities},
  author={Delgado, Karina Valdivia and Sanner, Scott and De Barros, Leliane Nunes},
  journal={Artificial Intelligence},
  volume={175},
  number={9},
  pages={1498--1527},
  year={2011},
  publisher={Elsevier}
}

@article{van2014generalization,
  title={Generalization and Exploration via Randomized Value Functions},
  author={Van Roy, Benjamin and Wen, Zheng},
  journal={arXiv preprint arXiv:1402.0635},
  year={2014}
}

@inproceedings{strehl2007model,
  title={Model-based reinforcement learning in factored-state {MDP}s},
  author={Strehl, Alexander},
  booktitle={Approximate Dynamic Programming and Reinforcement Learning, 2007. ADPRL 2007. IEEE International Symposium on},
  pages={103--110},
  year={2007},
  organization={IEEE}
}


@inproceedings{strehl2007efficient,
  title={Efficient structure learning in factored-state {MDP}s},
  author={Strehl, Alexander and Diuk, Carlos and Littman, Michael},
  booktitle={AAAI},
  volume={7},
  pages={645--650},
  year={2007}
}


@article{guestrin2003efficient,
  title={Efficient solution algorithms for factored {MDP}s},
  author={Guestrin, Carlos and Koller, Daphne and Parr, Ronald and Venkataraman, Shobha},
  journal={J. Artif. Intell. Res.(JAIR)},
  volume={19},
  pages={399--468},
  year={2003}
}


@article{boutilier2000stochastic,
  title={Stochastic dynamic programming with factored representations},
  author={Boutilier, Craig and Dearden, Richard and Goldszmidt, Mois{\'e}s},
  journal={Artificial Intelligence},
  volume={121},
  number={1},
  pages={49--107},
  year={2000},
  publisher={Elsevier}
}


@incollection{ghahramani1998learning,
  title={Learning dynamic Bayesian networks},
  author={Ghahramani, Zoubin},
  booktitle={Adaptive processing of sequences and data structures},
  pages={168--197},
  year={1998},
  publisher={Springer}
}

@inproceedings{szita2009optimistic,
  title={Optimistic initialization and greediness lead to polynomial time learning in factored {MDP}s},
  author={Szita, Istv{\'a}n and L{\H{o}}rincz, Andr{\'a}s},
  booktitle={Proceedings of the 26th Annual International Conference on Machine Learning},
  pages={1001--1008},
  year={2009},
  organization={ACM}
}

@article{weissman2003inequalities,
  title={Inequalities for the {L}1 deviation of the empirical distribution},
  author={Weissman, Tsachy and Ordentlich, Erik and Seroussi, Gadiel and Verdu, Sergio and Weinberger, Marcelo J},
  journal={Hewlett-Packard Labs, Tech. Rep},
  year={2003}
}

@article{clarke1990information,
  title={Information-theoretic asymptotics of Bayes methods},
  author={Clarke, Bertrand and Barron, Andrew},
  journal={Information Theory, IEEE Transactions on},
  volume={36},
  number={3},
  pages={453--471},
  year={1990},
  publisher={IEEE}
}

@inproceedings{guestrin2001max,
  title={Max-norm projections for factored {MDP}s},
  author={Guestrin, Carlos and Koller, Daphne and Parr, Ronald},
  booktitle={IJCAI},
  volume={1},
  pages={673--682},
  year={2001}
}


@inproceedings{koller2000policy,
  title={Policy iteration for factored {MDP}s},
  author={Koller, Daphne and Parr, Ronald},
  booktitle={Proceedings of the Sixteenth conference on Uncertainty in artificial intelligence},
  pages={326--334},
  year={2000},
  organization={Morgan Kaufmann Publishers Inc.}
}

@inproceedings{kearns1999efficient,
  title={Efficient reinforcement learning in factored {MDP}s},
  author={Kearns, Michael and Koller, Daphne},
  booktitle={IJCAI},
  volume={16},
  pages={740--747},
  year={1999}
}

@article{osband2013more,
  title={{(More) Efficient Reinforcement Learning via Posterior Sampling}},
  author={Osband, Ian and Russo, Daniel and Van Roy, Benjamin},
  journal={Advances in Neural Information Processing Systems},
  year={2013}
}

@book{cover1991elements,
  title={Elements of information theory. telecommunications},
  author={Cover, T and Thomas, J and Proakis, John G and Salehi, Masoud and Morelos-Zaragoza, Robert H},
  year={1991},
  publisher={Wiley series}
}


@article{gossner2008entropy,
  title={Entropy bounds on Bayesian learning},
  author={Gossner, Olivier and Tomala, Tristan},
  journal={Journal of mathematical economics},
  volume={44},
  number={1},
  pages={24--32},
  year={2008},
  publisher={Elsevier}
}

@book{lehmann1998theory,
  title={Theory of point estimation},
  author={Lehmann, Erich Leo and Casella, George},
  volume={31},
  year={1998},
  publisher={Springer}
}

@inproceedings{abbasi2009forced,
  title={Forced-exploration based algorithms for playing in stochastic linear bandits},
  author={Abbasi-Yadkori, Yassin and Antos, Andr\a's and Szepesv{\'a}ri, Csaba},
  booktitle={COLT Workshop on On-line Learning with Limited Feedback},
  year={2009}
}

@inbook{gittins2011multi,
author = {Gittins, John and Glazebrook, Kevin and Weber, Richard},
publisher = {John Wiley \& Sons, Ltd},
isbn = {9780470980033},
title = {Multi-Armed Bandit Allocation Indices},
year = {2011}
}

@article{bubeck2012regret,
  title={Regret analysis of stochastic and nonstochastic multi-armed bandit problems},
  author={Bubeck, Sebastien and Cesa-Bianchi, Nicholas},
  journal={arXiv preprint arXiv:1204.5721},
  year={2012}
}

@article{ryzhov2012knowledge,
  title={The knowledge gradient algorithm for a general class of online learning problems},
  author={Ryzhov, Ilya and Powell, Warren and Frazier, Peter},
  journal={Operations Research},
  volume={60},
  number={1},
  pages={180--195},
  year={2012},
  publisher={INFORMS}
}

@inproceedings{aminbandits,
  title={Bandits, Query Learning, and the Haystack Dimension},
  author={Amin, K. and Kearns, M. and Syed, U.},
  booktitle={Proceedings of the 24th Annual Conference on Learning Theory (COLT)},
  year={2011}
}

@inproceedings{dudik2011efficient,
  title={Contextual bandit algorithms with supervised learning guarantees},
  author={Beygelzimer, A. and Langford, J. and Li, L. and Reyzin, L. and Schapire, R.E.},
  booktitle={Conference on Artificial Intelligence and Statistics (AISTATS)},
  publisher={JMLR Workshop and Conference Proceedings},
  volume={15},
  year={2011}
}

@article{agarwal2012contextual,
  title={Contextual Bandit Learning with Predictable Rewards},
  author={Agarwal, A. and Dud{\'i}k, M. and Kale, S. and Langford, J. and Schapire, R.E.},
  journal={arXiv preprint arXiv:1202.1334},
  year={2012}
}

@article{abbasi2011improved,
  title={Improved algorithms for linear stochastic bandits},
  author={Abbasi-Yadkori, Yassin and P{\'a}l, D{\'a}vid and Szepesv{\'a}ri, Csaba},
  journal={Advances in Neural Information Processing Systems},
  volume={24},
  year={2011}
}

@inproceedings{abbasi2012online,
  title={Online-to-confidence-set conversions and application to sparse stochastic bandits},
  author={Abbasi-Yadkori, Y. and Pal, D. and Szepesv{\'a}ri, C.},
  booktitle={Conference on Artificial Intelligence and Statistics (AISTATS)},
  year={2012}
}

@inproceedings{agrawal2012analysis,
  title={Analysis of {T}hompson Sampling for the multi-armed bandit problem},
  author={Agrawal, S. and Goyal, N.},
  journal={Proceedings of the 21st Annual Conference on Learning Theory (COLT)},
  year={2012}
}

@inproceedings{dani2008stochastic,
  title={Stochastic linear optimization under bandit feedback},
  author={Dani, V. and Hayes, T.P. and Kakade, S.M.},
  booktitle={Proceedings of the 21st Annual Conference on Learning Theory (COLT)},
  pages={355--366},
  year={2008}
}

@inproceedings{chapelle2011empirical,
  title={An empirical evaluation of {T}hompson sampling},
  author={Chapelle, O. and Li, L.},
  booktitle={Neural Information Processing Systems (NIPS)},
  year={2011}
}

@inproceedings{kaufmann2012bayesian,
  title={On {B}ayesian Upper Confidence Bounds for Bandit Problems},
  author={Kaufmann, E. and Capp{\'e}, O. and Garivier, A.},
  booktitle={Conference on Artificial Intelligence and Statistics (AISTATS)},
  year={2012}
}

@article{may2012optimistic,
  title={Optimistic {B}ayesian sampling in contextual-bandit problems},
  author={May, B.C. and Korda, N. and Lee, A. and Leslie, D.S.},
  journal={The Journal of Machine Learning Research},
  volume={98888},
  pages={2069--2106},
  year={2012},
  publisher={JMLR.org}
}

@inproceedings{kaufmann2012thompson,
  author = {E. Kauffmann and N. Korda and R. Munos},
  title = {Thompson Sampling: an Asymptotically Optimal Finite Time Analysis},
  booktitle = {International Conference on Algorithmic Learning Theory},
  pdf = {./files/Thompson_ALT2012.pdf},
  x-editorial-board = {yes},
  x-proceedings = {yes},
  x-international-audience = {yes},
  abstract = {The question of the optimality of Thompson Sampling for solving the stochastic multi-armed bandit problem had been open since 1933. In this paper we answer it positively for the case of Bernoulli rewards by providing the first finite-time analysis that matches the asymptotic rate given in the Lai and Robbins lower bound for the cumulative regret. The proof is accompanied by a numerical comparison with other optimal policies, experiments that have been lacking in the literature until now for the Bernoulli case.},
  year = {2012}
}

@article{KL-UCB2012,
  author = {O. Capp{\'e} and A. Garivier and O.-A. Maillard and R. Munos and G. Stoltz},
  title = {Kullback-{L}eibler Upper Confidence Bounds for Optimal Sequential Allocation},
  journal = {Submitted to the Annals of Statistics},
  pdf = {./files/klucb2012.pdf},
  x-editorial-board = {yes},
  x-proceedings = {yes},
  x-international-audience = {yes},
  year = {2012}
}

@article{scott2010modern,
  title={A modern {B}ayesian look at the multi-armed bandit},
  author={Scott, S.L.},
  journal={Applied Stochastic Models in Business and Industry},
  volume={26},
  number={6},
  pages={639--658},
  year={2010},
  publisher={Wiley Online Library}
}

@article{agrawal2013linear,
  title={Thompson Sampling for Contextual Bandits with Linear Payoffs},
  author={Agrawal, S. and Goyal, N.},
  journal={arXiv preprint arXiv:1209.3352},
  year={2012}
}

@article{agrawal2012further,
  title={Further Optimal Regret Bounds for {T}hompson Sampling},
  author={Agrawal, S. and Goyal, N.},
  journal={arXiv preprint arXiv:1209.3353},
  year={2012}
}

@article{filippi2010parametric,
  title={Parametric bandits: The generalized linear case},
  author={Filippi, S. and Capp{\'e}, O. and Garivier, A. and Szepesv{\'a}ri, C.},
  journal={Advances in Neural Information Processing Systems},
  volume={23},
  pages={1--9},
  year={2010}
}

@article{auer2003using,
  title={Using confidence bounds for exploitation-exploration trade-offs},
  author={Auer, P.},
  journal={The Journal of Machine Learning Research},
  volume={3},
  pages={397--422},
  year={2003},
  publisher={JMLR. org}
}

@article{KLucrl,
  author    = {S. Filippi and
               O. Capp{\'e} and
               A. Garivier},
  title     = {Optimism in Reinforcement Learning Based on Kullback-Leibler
               Divergence},
  journal   = {CoRR},
  volume    = {abs/1004.5229},
  year      = {2010},
  ee        = {http://arxiv.org/abs/1004.5229},
  bibsource = {DBLP, http://dblp.uni-trier.de}
}


@article{auer2002finite,
  title={Finite-time analysis of the multiarmed bandit problem},
  author={Auer, P. and Cesa-Bianchi, N. and Fischer, P.},
  journal={Machine learning},
  volume={47},
  number={2},
  pages={235--256},
  year={2002},
  publisher={Springer}
}

@article{auer2002nonstochastic,
  title={The nonstochastic multiarmed bandit problem},
  author={Auer, P. and Cesa-Bianchi, N. and Freund, Y. and Schapire, R.E.},
  journal={SIAM Journal on Computing},
  volume={32},
  number={1},
  pages={48--77},
  year={2002},
  publisher={SIAM}
}

@article{bubeck2011xarmed,
 title={X-armed bandits},
 author={Bubeck, S. and Munos, R. and Stoltz, G. and Szepesv{\'a}ri, C. },
 journal={Journal of Machine Learning Research},
 pages={1587â€“1627},
 volume={12},
 year={2011}
}

@inproceedings{liopen2012,
  title={Open Problem: Regret Bounds for {T}hompson Sampling},
  author={Li, L. and Chapelle, O.},
  booktitle={Proceedings of the 25th Annual Conference on Learning Theory (COLT)},
  year={2012}
}

@article{gittins1979dynamic,
  title={A dynamic allocation index for the discounted multiarmed bandit problem},
  author={Gittins, J.C. and Jones, D.M.},
  journal={Biometrika},
  volume={66},
  number={3},
  pages={561--565},
  year={1979},
  publisher={Biometrika Trust}
}

@inproceedings{kleinberg2008multi,
  title={Multi-armed bandits in metric spaces},
  author={Kleinberg, R. and Slivkins, A. and Upfal, E.},
  booktitle={Proceedings of the 40th ACM Symposium on Theory of Computing},
  year={2008}
}

@article{lai1985asymptotically,
  title={Asymptotically efficient adaptive allocation rules},
  author={Lai, T.L. and Robbins, H.},
  journal={Advances in applied mathematics},
  volume={6},
  number={1},
  pages={4--22},
  year={1985},
  publisher={Elsevier}
}

@article{mersereau2009structured,
  title={A structured multiarmed bandit problem and the greedy policy},
  author={Mersereau, A.J. and Rusmevichientong, P. and Tsitsiklis, J.N.},
  journal={Automatic Control, IEEE Transactions on},
  volume={54},
  number={12},
  pages={2787--2802},
  year={2009},
  publisher={IEEE}
}

@article{rusmevichientong2010linearly,
  title={Linearly parameterized bandits},
  author={Rusmevichientong, P. and Tsitsiklis, J.N.},
  journal={Mathematics of Operations Research},
  volume={35},
  number={2},
  pages={395--411},
  year={2010},
  publisher={INFORMS}
}

@article{srinivas2012information,
author={Srinivas, N. and Krause, A. and Kakade, S.M. and Seeger, M.},
journal={Information Theory, IEEE Transactions on},
title={Information-Theoretic Regret Bounds for {G}aussian Process Optimization in the Bandit Setting},
year={2012},
month={may },
volume={58},
number={5},
pages={3250 -3265},
keywords={Bayesian methods;Convergence;{G}aussian processes;Kernel;Noise;Optimization;Temperature sensors;{G}aussian processes;Hilbert spaces;information theory;{G}aussian process optimization;bandit setting;cumulative regret;information-theoretic regret bounds;intuitive {G}aussian process upper confidence bound algorithm;multiarmed bandit problem;payoff function;reproducing kernel Hilbert space;sublinear regret bounds;Bandit problems;Bayesian prediction;{G}aussian process (GP);experimental design;information gain;nonparametric statistics;online learning;regret bound;statistical learning;},
doi={10.1109/TIT.2011.2182033},
ISSN={0018-9448},}


@article{thompson1933,
author={William Thompson},
 title={On the likelihood that one unknown probability exceeds another in view of the evidence of two samples},
 journal={Biometrika},
 year={1933},
 volume={25},
 number={3/4},
 pages={285-294}
}


@article{sahni1974,
 title={Computationally related problems},
 author={Sahni, A.},
 journal={SIAM Journal on Computing},
 year={1974},
 volume={3},
 number={4},
 pages={262-279}
}


@article{kaelbling1996reinforcement,
  title={Reinforcement learning: A survey},
  author={Kaelbling, Leslie Pack and Littman, Michael L and Moore, Andrew W},
  journal={arXiv preprint cs/9605103},
  year={1996}
}


@inproceedings{strens2000bayesian,
  title={A {B}ayesian framework for reinforcement learning},
  author={Malcom Strens},
  booktitle={Proceedings of the 17th International Conference on Machine Learning},
  pages={943--950},
  year={2000}
}

@book{kumar1986stochastic,
  title={Stochastic systems: estimation, identification and adaptive control},
  author={P. R. Kumar and P. Varaiya},
  year={1986},
  publisher={Prentice-Hall, Inc.}
}

@article{burnetas1997optimal,
  title={Optimal adaptive policies for {M}arkov decision processes},
  author={Apostolos Burnetas and Michael  Katehakis},
  journal={Mathematics of Operations Research},
  volume={22},
  number={1},
  pages={222--255},
  year={1997},
  publisher={INFORMS}
}

@article{kearns2002near,
  title={Near-optimal reinforcement learning in polynomial time},
  author={Michael Kearns and Satinder Singh},
  journal={Machine Learning},
  volume={49},
  number={2-3},
  pages={209--232},
  year={2002},
  publisher={Springer}
}

@article{brafman2003r,
  title={R-max-a general polynomial time algorithm for near-optimal reinforcement learning},
  author={Ronen Brafman and Moshe Tennenholtz},
  journal={The Journal of Machine Learning Research},
  volume={3},
  pages={213--231},
  year={2003},
  publisher={JMLR. org}
}

@phdthesis{kakade2003sample,
  title={On the sample complexity of reinforcement learning},
  author={S. M. Kakade},
  year={2003},
  school={University of London}
}

@inproceedings{bartlett2009regal,
  title={REGAL: A regularization based algorithm for reinforcement learning in weakly communicating {MDP}s},
  author={Peter Bartlett and Ambuj Tewari},
  booktitle={Proceedings of the Twenty-Fifth Conference on Uncertainty in Artificial Intelligence},
  pages={35--42},
  year={2009},
  organization={AUAI Press}
}

@article{martin1967bayesian,
  title={Bayesian decision problems and {M}arkov chains},
  author={Martin, James John},
  year={1967},
  publisher={Wiley}
}

@inproceedings{wang2005bayesian,
  title={Bayesian sparse sampling for on-line reward optimization},
  author={T. Wang and Lizotte, D. and Bowling, M. and Schuurmans, D.},
  booktitle={Proceedings of the 22nd international conference on Machine learning},
  pages={956--963},
  year={2005},
  organization={ACM}
}

@article{mundhenk2000complexity,
  title={Complexity of finite-horizon {M}arkov decision process problems},
  author={Mundhenk, Martin and Goldsmith, Judy and Lusena, Christopher and Allender, Eric},
  journal={Journal of the ACM (JACM)},
  volume={47},
  number={4},
  pages={681--720},
  year={2000},
  publisher={ACM}
}

@inproceedings{kolter2009near,
  title={Near-{B}ayesian exploration in polynomial time},
  author={J. Z. Kolter and A. Y. Ng},
  booktitle={Proceedings of the 26th Annual International Conference on Machine Learning},
  pages={513--520},
  year={2009},
  organization={ACM}
}

@inproceedings{dearden1999model,
  title={Model based {B}ayesian exploration},
  author={Dearden, Richard and Friedman, Nir and Andre, David},
  booktitle={Proceedings of the fifteenth Conference on Uncertainty in Artificial Intelligence},
  pages={150--159},
  year={1999},
  organization={Morgan Kaufmann Publishers Inc.}
  }

  @inproceedings{asmuth2009bayesian,
  title={A {B}ayesian sampling approach to exploration in reinforcement learning},
  author={Asmuth, John and Li, Lihong and Littman, Michael L and Nouri, Ali and Wingate, David},
  booktitle={Proceedings of the Twenty-Fifth Conference on Uncertainty in Artificial Intelligence},
  pages={19--26},
  year={2009},
  organization={AUAI Press}
}

@article{russo2013,
  author    = {D. Russo and
               B. Van Roy},
  title     = {Learning to Optimize Via Posterior Sampling},
  journal   = {CoRR},
  volume    = {abs/1301.2609},
  year      = {2013},
  ee        = {http://arxiv.org/abs/1301.2609},
  bibsource = {DBLP, http://dblp.uni-trier.de}
}

@article{strehl2008analysis,
  title={An analysis of model-based interval estimation for {M}arkov decision processes},
  author={Strehl, A. L. and Littman, M. L.},
  journal={Journal of Computer and System Sciences},
  volume={74},
  number={8},
  pages={1309--1331},
  year={2008},
  publisher={Elsevier}
}

@article{guez2012efficient,
  title={Efficient bayes-adaptive reinforcement learning using sample-based search},
  author={Guez, A. and Silver, D. and Dayan, P.},
  journal={arXiv preprint arXiv:1205.3109},
  year={2012}
}

@inproceedings{asmuth2011approaching,
  title={Approaching Bayes-optimalilty using Monte-Carlo tree search},
  author={Asmuth, J. and Littman, M. L.},
  booktitle={Proc. 21st Int. Conf. Automat. Plan. Sched., Freiburg, Germany},
  year={2011}
}

