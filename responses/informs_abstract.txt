Any learning algorithm over MDPs will have worst-case regret which grows with the square root of the number of state-action pairs. In many cases of interest the state and action spaces are so huge that it is impossible to guarantee good performance on any reasonable time frame. We show that, if the system can be represented as a factored MDP, we can obtain regret bounds polynomial in the number of parameters of the MDP, which may be exponentially smaller than the state or action spaces.